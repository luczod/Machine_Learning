{
    "cells": [
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {
                "colab_type": "text",
                "id": "QJdrJJQUv3-k"
            },
            "source": [
                "## Upper Confidence Bound (UCB)\n",
                "\n",
                "- Reinforcement learning including concepts such as agent, environment, policy, action, state and reward.\n",
                "- The Multi-Armed Bandit Problem\n",
                "- Exploration and Exploitation\n",
                "- When deciding what state it should choose next, an agent faces a trade-off between exploration and exploitation. Exploration involves choosing new states that the agent hasnâ€™t chosen or has chosen fewer times till then. Exploitation involves making a decision regarding the next state from its experiences so far.\n",
                "- Real time process\n",
                "- Minimum number of rounds\n",
                "- Deterministic\n",
                "- Requiees update at every round\n"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {
                "colab_type": "text",
                "id": "2XCjepjJwEv-"
            },
            "source": [
                "### Importing the libraries\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "colab": {},
                "colab_type": "code",
                "id": "l_mBkG3YwNTt"
            },
            "outputs": [],
            "source": [
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "import pandas as pd\n"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {
                "colab_type": "text",
                "id": "npqlXjaNwYTv"
            },
            "source": [
                "### Importing the dataset\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "colab": {},
                "colab_type": "code",
                "id": "HMJfUVLVwcFc"
            },
            "outputs": [],
            "source": [
                "dataset = pd.read_csv('Ads_CTR_Optimisation.csv')\n"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {
                "colab_type": "text",
                "id": "PaSbots_wfoB"
            },
            "source": [
                "### Implementing UCB\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "colab": {},
                "colab_type": "code",
                "id": "V1K7jgDFwkRd"
            },
            "outputs": [],
            "source": [
                "import math\n",
                "N = 10000  # main variable\n",
                "d = 10\n",
                "ads_selected = []\n",
                "numbers_of_selections = [0] * d\n",
                "sums_of_rewards = [0] * d\n",
                "total_reward = 0\n",
                "\n",
                "for n in range(0, N):\n",
                "    ad = 0\n",
                "    max_upper_bound = 0\n",
                "    for i in range(0, d):\n",
                "        if (numbers_of_selections[i] > 0):\n",
                "            average_reward = sums_of_rewards[i] / numbers_of_selections[i]\n",
                "            delta_i = math.sqrt(3/2 * math.log(n + 1) /\n",
                "                                numbers_of_selections[i])\n",
                "            upper_bound = average_reward + delta_i\n",
                "        else:\n",
                "            upper_bound = 1e400  # trick to use infinity\n",
                "        if upper_bound > max_upper_bound:\n",
                "            max_upper_bound = upper_bound\n",
                "            ad = i\n",
                "    ads_selected.append(ad)\n",
                "    numbers_of_selections[ad] = numbers_of_selections[ad] + 1\n",
                "    reward = dataset.values[n, ad]\n",
                "    sums_of_rewards[ad] = sums_of_rewards[ad] + reward\n",
                "    total_reward = total_reward + reward\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print('ads_selected:', ads_selected)\n",
                "print('numbers_of_selections:', numbers_of_selections)\n",
                "print('sums_of_rewards:', sums_of_rewards)\n",
                "print('total_reward:', total_reward)\n"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {
                "colab_type": "text",
                "id": "AXftWcjDwsYj"
            },
            "source": [
                "### Visualizing the results\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "colab": {
                    "base_uri": "https://localhost:8080/",
                    "height": 295
                },
                "colab_type": "code",
                "executionInfo": {
                    "elapsed": 2141,
                    "status": "ok",
                    "timestamp": 1586416167859,
                    "user": {
                        "displayName": "Hadelin de Ponteves",
                        "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhEuXdT7eQweUmRPW8_laJuPggSK6hfvpl5a6WBaA=s64",
                        "userId": "15047218817161520419"
                    },
                    "user_tz": -240
                },
                "id": "eVyD_EDXwtkK",
                "outputId": "8cb6b886-8482-43be-e4ee-0313c17508c6"
            },
            "outputs": [],
            "source": [
                "plt.hist(ads_selected)\n",
                "plt.title('Histogram of ads selections')\n",
                "plt.xlabel('Ads')\n",
                "plt.ylabel('Number of times each ad was selected')\n",
                "plt.show()\n"
            ]
        }
    ],
    "metadata": {
        "colab": {
            "authorship_tag": "ABX9TyMz+roSgJuEsprRsPKmwoVD",
            "collapsed_sections": [],
            "name": "Upper Confidence Bound",
            "provenance": [],
            "toc_visible": true
        },
        "kernelspec": {
            "display_name": "Python 3",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.12.3"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 0
}
